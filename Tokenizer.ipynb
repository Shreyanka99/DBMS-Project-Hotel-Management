{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKz3NFZa13tBLaKh53nBnV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shreyanka99/DBMS-Project-Hotel-Management/blob/main/Tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ideb2rMbLU8a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"I love my dog\",\n",
        "    \"I love my dog!!\",\n",
        "    \"I love my cat\",\n",
        "    \"I think I'm an amazing mom to my dog.\",\n",
        "    \"I think i'm an Amazing mom to my cat\",\n",
        "]\n",
        "\n",
        "tokenizer= Tokenizer(num_words=100 , oov_token=\"<OOV>\") #max number of words\n",
        "tokenizer.fit_on_texts(sentences) #used to train the neural network\n",
        "word_index = tokenizer.word_index\n",
        "print(\"Word Indexes:\")\n",
        "print(word_index)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences) #Gets the word index to create sequences.\n",
        "print(\"\\nSequences\")\n",
        "print(sequences)\n",
        "\n",
        "padded = pad_sequences(sequences, maxlen =7 , padding = 'post')\n",
        "print(\"\\nPadded Sequences\")\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPZlYuvtLy0i",
        "outputId": "1403140e-2254-4a54-88c9-685b8711a4c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Indexes:\n",
            "{'<OOV>': 1, 'i': 2, 'my': 3, 'love': 4, 'dog': 5, 'cat': 6, 'think': 7, \"i'm\": 8, 'an': 9, 'amazing': 10, 'mom': 11, 'to': 12}\n",
            "\n",
            "Sequences\n",
            "[[2, 4, 3, 5], [2, 4, 3, 5], [2, 4, 3, 6], [2, 7, 8, 9, 10, 11, 12, 3, 5], [2, 7, 8, 9, 10, 11, 12, 3, 6]]\n",
            "\n",
            "Padded Sequences\n",
            "[[ 2  4  3  5  0  0  0]\n",
            " [ 2  4  3  5  0  0  0]\n",
            " [ 2  4  3  6  0  0  0]\n",
            " [ 8  9 10 11 12  3  5]\n",
            " [ 8  9 10 11 12  3  6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data={\n",
        "    \"My Dog is very friendly\",\n",
        "    \"He loves my mom.\"\n",
        "}\n",
        "print(word_index)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data)\n",
        "print(test_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlrgA_RjMeDo",
        "outputId": "e87e5045-fb14-46cc-ea3a-91a7833ec72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<OOV>': 1, 'i': 2, 'my': 3, 'love': 4, 'dog': 5, 'cat': 6, 'think': 7, \"i'm\": 8, 'an': 9, 'amazing': 10, 'mom': 11, 'to': 12}\n",
            "[[3, 5, 1, 1, 1], [1, 1, 3, 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ys9Sb7y_O6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART 2"
      ],
      "metadata": {
        "id": "mBt8HNE6_Pp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA IN THE FORM OF : WHERE 0 - not sarcastic, 1 - is sarcastic\n",
        "\n",
        "# [\n",
        "# {\"article_link\": \"https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5\", \"headline\": \"former versace store clerk sues over secret 'black code' for minority shoppers\", \"is_sarcastic\": 0},\n",
        "# {\"article_link\": \"https://www.huffingtonpost.com/entry/roseanne-revival-review_us_5ab3a497e4b054d118e04365\", \"headline\": \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\", \"is_sarcastic\": 0},\n",
        "# {\"article_link\": \"https://local.theonion.com/mom-starting-to-fear-son-s-web-series-closest-thing-she-1819576697\", \"headline\": \"mom starting to fear son's web series closest thing she will have to grandchild\", \"is_sarcastic\": 1},\n",
        "# {\"article_link\": \"https://politics.theonion.com/boehner-just-wants-wife-to-listen-not-come-up-with-alt-1819574302\", \"headline\": \"boehner just wants wife to listen, not come up with alternative debt-reduction ideas\", \"is_sarcastic\": 1},\n",
        "# {\"article_link\": \"https://www.huffingtonpost.com/entry/jk-rowling-wishes-snape-happy-birthday_us_569117c4e4b0cad15e64fdcb\", \"headline\": \"j.k. rowling wishes snape happy birthday in the most magical way\", \"is_sarcastic\": 0},\n",
        "# {\"article_link\": \"https://www.huffingtonpost.com/entry/advancing-the-worlds-women_b_6810038.html\", \"headline\": \"advancing the world's women\", \"is_sarcastic\": 0},\n",
        "# {\"article_link\": \"https://www.huffingtonpost.com/entry/how-meat-is-grown-in-a-lab_us_561d1189e4b0c5a1ce607e86\", \"headline\": \"the fascinating case for eating lab-grown meat\", \"is_sarcastic\": 0}"
      ],
      "metadata": {
        "id": "hQeC7l-dTBLl"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json \n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "nO2hbKJP_P47"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/learning-datasets/sarcasm.json \\\n",
        "    -O /tmp/sarcasm.json\n",
        "\n",
        "with open(\"/tmp/sarcasm.json\", 'r') as f:\n",
        "    datastore = json.load(f)\n",
        "\n",
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "for item in datastore:\n",
        "    sentences.append(item['headline'])\n",
        "    labels.append(item['is_sarcastic'])"
      ],
      "metadata": {
        "id": "RMwRdfmKpM5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad411f35-e434-4eca-f822-03edf524a7bd"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-06 15:05:47--  https://storage.googleapis.com/learning-datasets/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.111.128, 142.251.163.128, 142.251.167.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.111.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘/tmp/sarcasm.json’\n",
            "\n",
            "\r/tmp/sarcasm.json     0%[                    ]       0  --.-KB/s               \r/tmp/sarcasm.json   100%[===================>]   5.38M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-06-06 15:05:47 (204 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "training_size = 20000\n",
        "embedding_dim = 16 \n",
        "max_len = 100\n",
        "num_epochs = 30"
      ],
      "metadata": {
        "id": "Zg3Jyj7W83Fw"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_sentences = sentences[0:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "\n",
        "training_labels = labels[0:training_size]\n",
        "testing_labels = labels[training_size:]"
      ],
      "metadata": {
        "id": "wnVCHGn0_1Lb"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token = \"<OOV>\")\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_pads = pad_sequences(training_sequences, maxlen=max_len, padding= \"post\", truncating= \"post\")\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_pads = pad_sequences(testing_sequences, maxlen=max_len, padding= \"post\", truncating= \"post\")\n"
      ],
      "metadata": {
        "id": "Yh4HlDZtAcHs"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_len),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SVGuhD6xArNZ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPaYIZS_DSiD",
        "outputId": "830dfc33-ee09-4055-b46e-93bb9cacb219"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 16)           160000    \n",
            "                                                                 \n",
            " global_average_pooling1d_2   (None, 16)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 24)                408       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,433\n",
            "Trainable params: 160,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Need this block to get it to work with TensorFlow 2.x\n",
        "import numpy as np\n",
        "training_pads = np.array(training_pads)\n",
        "training_labels = np.array(training_labels)\n",
        "testing_pads = np.array(testing_pads)\n",
        "testing_labels = np.array(testing_labels)"
      ],
      "metadata": {
        "id": "kKXKQQV7Fski"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(training_pads, training_labels, epochs=30, validation_data=(testing_pads, testing_labels), verbose=2)"
      ],
      "metadata": {
        "id": "bViXlAW7DjKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sentences = [\n",
        "    \"WOW, oh really?\",\n",
        "    \"Im not impressed!\",\n",
        "    \"That's great\",\n",
        "    \"It is a beautiful day\"\n",
        "]\n",
        "\n",
        "new_sequences = tokenizer.texts_to_sequences(new_sentences)\n",
        "new_padded = pad_sequences(new_sequences, maxlen=100,padding=\"post\", truncating='post')\n",
        "\n",
        "model.predict(new_padded)"
      ],
      "metadata": {
        "id": "NpjBi49fEza1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3cf1f1e-3a99-48de-9379-8ccb69169601"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 149ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.04717137e-02],\n",
              "       [9.99778748e-01],\n",
              "       [5.53088129e-01],\n",
              "       [1.12444286e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_ywH-AgQc38",
        "outputId": "e99cbee4-3460-4d49-a168-13a013b41d34"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-68-7ce91c61d20c>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  new_sequences = np.array(new_sequences)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gaB2gwDyRQk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jFRfEMRERTCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4QnBcU2oN9a1"
      }
    }
  ]
}